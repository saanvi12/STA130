{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3ac3cb",
   "metadata": {},
   "source": [
    "# 1. What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically? What would you describe is the key \"criteria\" defining what a good null hypothesis is? And what is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing?\n",
    "\n",
    "The key factor differentiating testable ideas from non-testable ones in statistics is the ability to collect data that can be analyzed to provide evidence for or against an idea.\n",
    "<p>\n",
    "A good null hypothesis should be:\n",
    "<p>\n",
    "Testable: We need data that can potentially contradict it.<p>\n",
    "Default/Uninteresting: It often represents the status quo or a lack of effect.<p>\n",
    "A \"Straw Man\": something we might not actually believe, but it sets up a framework to potentially disprove and move towards a more interesting conclusion.<p>\n",
    "The null hypothesis (H<sub>0</sub>) is our initial assumption, often representing \"no effect\" or the default belief. The alternative hypothesis (H<sub>A</sub>) simply states that the null hypothesis is false. It doesn't specify how it's false, just that it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f905fb",
   "metadata": {},
   "source": [
    "# 2. \"It is important to note that outcomes of tests refer to the population parameter, rather than the sample statistic! As such, the result that we get is for the population.\" In terms of the distinctions between the concepts of [...] how would you describe what the sentence above means?\n",
    "\n",
    "Observed Values (xi): These are the individual data points we collect in our sample. For example, if we're measuring the height of students, each student's height is an x<sub>i</sub>.\n",
    "<p>\n",
    "Sample Average (x̄): This is the average of all the observed values in our sample. It gives us an estimate of the average height of students in our sample.\n",
    "<p>\n",
    "Population Average (μ): This is the true average value we're interested in, but we usually can't measure it directly (e.g., the average height of all students, not just those in our sample).\n",
    "Hypothesized Value (μ0): This is the specific value of the population average we're testing in our null hypothesis (H<sub>0</sub>). For example, we might hypothesize that the average height of all students (μ) is 5 feet 8 inches (μ<sub>0</sub>).\n",
    "<p>\n",
    "The sentence means that while we use data from our sample to perform a hypothesis test, the conclusions we draw apply to the population parameter (μ), not just the sample statistic (x̄)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8963fc",
   "metadata": {},
   "source": [
    "# 3. \"Imagine a world where the null hypothesis is true\" when calculating a p-value? Explain why this is.\n",
    "\n",
    "We \"imagine a world where the null hypothesis is true\" when calculating a p-value because the p-value is specifically defined as the probability of observing our data (or more extreme data) if the null hypothesis were actually true.\n",
    "<p>\n",
    "Sampling Distribution Under H0: To calculate a p-value, we need to consider the sampling distribution of our test statistic under the null hypothesis. This distribution shows us the range of values we'd expect for our statistic due to random chance alone if the null hypothesis were true.\n",
    "<p>\n",
    "Comparing Our Observed Statistic: We then compare our observed statistic to this sampling distribution. If our observed statistic falls in an extreme tail of the distribution (meaning it's unlikely to occur by chance if H<sub>0</sub> were true), we get a small p-value, providing evidence against the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa8353",
   "metadata": {},
   "source": [
    "# 4. A smaller p-value makes the null hypothesis look more ridiculous. Explain why this is.\n",
    "\n",
    "A smaller p-value makes the null hypothesis look more \"ridiculous\" because it means our observed data is increasingly unlikely to have occurred by chance if the null hypothesis were actually true. A small p-value indicates that our observed test statistic falls far out in the tail of the sampling distribution under the null hypothesis.This suggests that our data is so unusual under the assumption of H<sub>0</sub> that it's more plausible that H<sub>0</sub> is actually false. The smaller the p-value, the stronger the evidence against H<sub>0</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65ddf8",
   "metadata": {},
   "source": [
    "# 5. Gunturkun kissing couples experiment\n",
    "\n",
    "We are testing the null hypothesis ￼ that humans have no preference for left or right head tilt when kissing, meaning the probability of tilting either left or right is 50/50. <p>\n",
    "The data from the study shows that 80 out of 124 couples tilted their heads to the right.\n",
    "We assume a binomial distribution for this problem since each couple’s head tilt can be considered a Bernoulli trial (tilt right or not).\n",
    "Under ￼, the probability of tilting right is 0.5 (50%).\n",
    "Number of right tilts (successes): 80\n",
    "Total number of couples (trials): 124\n",
    "I used the binomial test to compute the probability of observing 80 or more couples tilting their heads to the right, given the null hypothesis ￼ (50% chance of either tilt).\n",
    "The alternative hypothesis is one-sided (greater), since we are interested in whether more couples tilt to the right than expected by random chance.\n",
    "Using the scipy.stats.binom_test() function in Python, I computed the p-value, which turned out to be 0.00078.\n",
    "<p>\n",
    "import scipy.stats as stats<p>\n",
    "\n",
    "Number of successes (tilt right), total observations, and the null hypothesis probability (50%)<p>\n",
    "successes = 80<p>\n",
    "n = 124<p>\n",
    "null_hypothesis_prob = 0.5<p>\n",
    "\n",
    "Perform a binomial test<p>\n",
    "p_value = stats.binom_test(successes, n, null_hypothesis_prob, alternative='greater')<p>\n",
    "print(p_value)<p>\n",
    "This p-value is very small, indicating that it’s highly unlikely to observe this many couples tilting their heads to the right if the true probability were 50%. Therefore, we reject the null hypothesis and conclude that there is very strong evidence against it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031c8f1",
   "metadata": {},
   "source": [
    "# 6. Can a smaller p-value definitively prove that the null hypothesis is false? Is it possible to definitively prove that Fido (from the \"second pre-lecture video\") is innocent using a p-value? Is it possible to difinitively prove that Fido is guilty using a p-value? How low or high does a p-value have to be to definitely prove one or the other?\n",
    "It is not possible to definitively prove that Fido is innocent. the P-value just states if our evidence makes the null hypothesis look ridiculous or not. A smaller P-value does not definitively prove the null hypothesis to be false as there is always some chance that it is true, and a larger P-value doesn't automatically prove it as true because it just means that there is not enough evidence to reject it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa351229",
   "metadata": {},
   "source": [
    "# 7. Describe (perhaps with the help of your ChatBot) what changed in the code; how this changes the interpretation of the hypothesis test; and whether or not we should indeed expect the p-value to be smaller in the \"one tailed\" versus \"two tailed\" analysis.\n",
    "\n",
    "\n",
    "p-value Calculation: In the original (two-sided) test, we checked whether the observed statistic was extreme in both directions (greater or less than the null hypothesis value). <p>In the updated one-sided test, we only check whether the observed mean is greater than the null hypothesis value (65 in this case).<p>\n",
    "Condition for One-sided Test: The condition bootstrapped_means_under_H0 >= observed_mean is used to calculate the p-value, meaning we only consider the proportion of bootstrapped means that are greater than or equal to the observed mean.<p>\n",
    "Removal of Symmetry:We removed the calculation for checking “as or more extreme” values on both sides (less than and greater than the null hypothesis). The symmetric region in a two-sided test (for values lower than the null) was eliminated.<p>\n",
    "One-sided Test Interpretation: The one-sided test is only concerned with whether the observed statistic (mean) is greater than the null hypothesis value (the hypothesized mean).<p>This changes the interpretation of the test. For example, if the one-sided p-value is small, it indicates strong evidence that the sample mean is significantly larger than the null hypothesis mean.<p>\n",
    "Comparison to Two-sided Test: A two-sided test is more conservative because it tests for both directions (whether the statistic is either greater or smaller than the hypothesized value).<p>As a result, a two-sided test generally requires stronger evidence (a larger deviation from the null) to reject the null hypothesis.\n",
    "<p>\n",
    "Should the p-value be Smaller in the One-tailed Test?<p>\n",
    "Yes, we generally expect the p-value to be smaller in a one-tailed test compared to a two-tailed test.<p>\n",
    "This is because the one-tailed test only considers the probability of the observed statistic in one direction (greater than or equal to the null value), whereas the two-tailed test looks for extreme values in both directions (greater and less).<p>\n",
    "Since we’re excluding half of the distribution (the side where values are less than the null), the probability of finding values as extreme as the observed one is naturally smaller, leading to a smaller p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf51c23",
   "metadata": {},
   "source": [
    "# 8. Report\n",
    "\n",
    "Tea Experiment Analysis Report\n",
    "\n",
    "Problem Introduction\n",
    "\n",
    "The problem posed is a modern adaptation of Fisher’s famous Tea Experiment, originally conducted to test whether Dr. Muriel Bristol could reliably identify the sequence of tea and milk pouring. The current scenario involves 80 students from STA130, 49 of whom correctly identified whether tea or milk was poured first. The question we aim to answer is whether this result occurred by random guessing or if there is evidence that the students have a better-than-chance ability to identify the pouring order.\n",
    "\n",
    "This analysis will involve statistical hypothesis testing, focusing on whether we can reject the null hypothesis (that the students are guessing) in favor of the alternative (that they have a better-than-chance ability).\n",
    "\n",
    "Relationship to Fisher’s Original Experiment\n",
    "\n",
    "<p>Fisher’s experiment involved 8 cups, while this modern adaptation includes a larger sample of 80 students.\n",
    "<p>Population Difference: In Fisher’s experiment, the population was one person (Dr. Bristol) with potentially unique sensory abilities, whereas in this experiment, we are sampling from a student population with varied sensory abilities and no prior expectation of expertise.<p>\n",
    "\n",
    "Null Hypothesis (H₀) and Alternative Hypothesis (H₁)<p>\n",
    "H₀ (Null Hypothesis): The proportion of students who can correctly identify whether tea or milk was poured first is equal to 0.5 (i.e., the students are randomly guessing).<p> H_0: p = 0.5 <p>\n",
    "The proportion of students who can correctly identify the order is greater than 0.5 (i.e., the students have some ability to correctly identify the order more often than random guessing).<p>  H_1: p > 0.5 <p>\n",
    "<p>\n",
    "   \n",
    "\t•\tNull Hypothesis: Students have no special ability to tell if tea or milk was poured first; they are just randomly guessing with a 50% chance of being correct.<p>\n",
    "\t•\tAlternative Hypothesis: Students are better than random guessing and can correctly identify the order more often than 50% of the time.<p>\n",
    "\n",
    "Quantitative Analysis\n",
    "\n",
    "Observed Test Statistic:\n",
    "\n",
    "\t•\tSample Size (n): 80 students.\n",
    "\t•\tNumber of Correct Answers: 49 students.\n",
    "\t•\tObserved Proportion: ￼\n",
    "\n",
    "We want to test if this observed proportion is significantly greater than 0.5, as would be expected under random guessing. We’ll perform a one-sided hypothesis test using a binomial proportion model.\n",
    "\n",
    "Methodology\n",
    "\n",
    "To test the null hypothesis, we’ll use a simulation-based approach or a normal approximation to estimate the p-value.\n",
    "\n",
    "\t1.\tPopulation Parameter:\n",
    "\t•\tUnder the null hypothesis, the population proportion ￼ is 0.5 (random guessing).\n",
    "\t2.\tSampling Distribution of Proportion: \n",
    "\t•\tThe expected sampling distribution under the null hypothesis follows a binomial distribution:\n",
    "\t•\tMean =  p_0 = 0.5 \n",
    "\t•\tStandard Error (SE) =  \\sqrt{\\frac{p_0 (1 - p_0)}{n}} = \\sqrt{\\frac{0.5 \\times 0.5}{80}} = 0.0559 \n",
    "\t•\tWe can approximate this with a normal distribution.\n",
    "\n",
    "P-value Calculation:\n",
    "\n",
    "\t•\tWe calculate the z-score for the observed proportion:\n",
    "z = \\frac{\\hat{p} - p_0}{SE} = \\frac{0.6125 - 0.5}{0.0559} \\approx 2.013\n",
    "\n",
    "Using a z-table or normal distribution function, we calculate the p-value as the area under the curve to the right of the observed z-score:\n",
    "\n",
    "p\\text{-value} = P(Z > 2.013) \\approx 0.0221\n",
    "\n",
    "This p-value indicates the probability of observing a result as extreme as 49 correct identifications, assuming the null hypothesis is true.\n",
    "\n",
    " z-score\n",
    "z = (p_hat - p_0) / SE\n",
    "\n",
    "<p>\n",
    "Findings<p>\n",
    "\n",
    "The p-value of 0.0221 is less than the conventional significance level of 0.05, meaning we have sufficient evidence to reject the null hypothesis.\n",
    "This result suggests that the students are better than random guessing in identifying whether tea or milk was poured first.\n",
    "\n",
    "<p>\n",
    "\n",
    "Since the alternative hypothesis was one-sided (students perform better than guessing), the p-value is smaller than it would have been in a two-tailed test. A two-tailed test would split the extreme results across both directions, leading to a larger p-value.\n",
    "\n",
    "<p>\n",
    "\n",
    "Based on the p-value, we reject the null hypothesis. This implies that STA130 students are significantly better than random guessing when determining the pouring order of tea and milk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68f482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed proportion: 0.6125\n",
      "Standard error: 0.05590169943749474\n",
      "Z-score: 2.0124611797498115\n",
      "P-value: 0.022085672454221217\n"
     ]
    }
   ],
   "source": [
    "#8. Code\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Given data\n",
    "n = 80  # total students\n",
    "successes = 49  # students who correctly identified the order\n",
    "p_hat = successes / n  # observed proportion\n",
    "p_0 = 0.5  # null hypothesis proportion\n",
    "\n",
    "# Calculate the standard error\n",
    "SE = np.sqrt((p_0 * (1 - p_0)) / n)\n",
    "\n",
    "# Calculate the z-score\n",
    "z = (p_hat - p_0) / SE\n",
    "\n",
    "# Calculate the one-sided p-value\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "print(f\"Observed proportion: {p_hat}\")\n",
    "print(f\"Standard error: {SE}\")\n",
    "print(f\"Z-score: {z}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156ad04",
   "metadata": {},
   "source": [
    "# 9. Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
